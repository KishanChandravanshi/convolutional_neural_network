{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.models as km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's talk about the libraries and why do we need them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential library basically means that we are going to create linear stack of layers where the output of neurons of one layer will serve as the input to the next layer and in this way we'll get something like tree with roots coming out and getting more complex, more info [keras](https://keras.io/getting-started/sequential-model-guide/).\n",
    "- Conv2D basically tries to fetch the important information from the image like curve, smoothness, or a particular patterns\n",
    "- MaxPooling2D work is to reduce the size of the matrix without compromising with the information that it contains\n",
    "- Flatten work is to convert the madrix to the one dimensional vector so that its each element could then be used as an input to the artificial neural network\n",
    "- Dense is used to add more layer to the ann efficiently i suppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising our classifier and telling that it has to be Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's break the above code and understand it \n",
    "- 32 represents the number of features detector that we want\n",
    "- (3, 3) represent thr strides size\n",
    "- input_shape = (64, 64, 3), here 64,64 represent the size of the image and 3 represent that it is a color image\n",
    "- activation = 'relu' actually we require a threshold to set, for example say we if some feature give us a value greater than the threshold then it fires up the neuron and if it is less then it does nothing, and this activation is calculated through 'relu', more on [StackOverflow](https://stackoverflow.com/questions/27319931/relu-and-dropout-in-cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Max Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Pooling as mentioned above is used to decrease the dimension of the matrix so that we only pass the relevant information and not garbage\n",
    "- pool_size: factors by which to downscale (vertical, horizontal). (2, 2) will halve the input in both spatial dimension. If only one integer is specified, the same window length will be used for both dimensions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll be adding another layer of convolution and Max Pooling so to further minimize the matrix and extract useful information out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), activation='relu')) \n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten()\n",
    "- Flatten will convert the matrix into a column vector which then can be feed to the ann(Artificial Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Connection - Artificial Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From here we have a single column vector that contains all the necessary information that we need to build a model\n",
    "- we'll be building layers of neurons that will try to figure out the information from these datas that we figured out during convolution\n",
    "- we'll predict the output and compare it to the truth value and we calculate the error\n",
    "- we'll try to minimize the error through backpropagation in which we actually try to modify weights\n",
    "- to get the most efficient weight we use stochastic gradient descent method, this method is like finding the minimum of the cost function or error function.\n",
    "- we'll also use dropout, in which some neurons are randomly shut down, this helps us in reducing over fitting\n",
    "- we'll run out the model again and again, epochs and will try to get the best model and will save it.\n",
    "- saving the model help us from running the model through all the process again and again, because these computations are actually time consuming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dense:\n",
    "- dense function actually helps us in creating the hidden layers efficiently\n",
    "- units means the number of neurons in the second layer, here it is 128\n",
    "- activation again tells us that when a neuron will fire up or lights up depending upon how much sure it is, and again we have choose 'relu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last neuron that will decide whether we classified dog or cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compile( )\n",
    "- adam is actually like stochastic gradient descent, [more](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)\n",
    "- loss here attributes about the loss function or cost function that we want to minimize using stochastic gradient descent\n",
    "- metrics, want the attribute, what we want to increase, here we want our model to increase in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the CNN with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First we need to have the sufficient data so that our model can learn properly, say we have less data then we can use keras ImageDataGenerator, what it does is it will alter the current image, like zoom, crop, tilt, so that we will have varieties of the single photo and it will enrich our data\n",
    "- we need to have the data classified for the training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ImageDataGenerator( )\n",
    "- we want all the pixel value to range from 0 to 1 i.e why we rescale it using rescale=1./255\n",
    "- shear_range, zoom_range, horizontal_flip these are the attributes that we can control to affect the images, so increasing zoom will result in a different photo than we had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .flow_from_directory( )\n",
    "- first parameter is to give the path of the folder where our images are stored\n",
    "- second parameter resize the images into 64 64 size\n",
    "- batch size actually means how much images it will consider in one batch and work on it\n",
    "- binary means that we either will have 0 or 1 result, i.e cat or dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the data to the classifier, to learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch=8000,\n",
    "                         epochs=30,\n",
    "                         validation_data=test_set,\n",
    "                         validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .fit_generator( )\n",
    "- first parameter takes the set to which we want to train the data\n",
    "- second parameter takes the steps_per_epochs, i.e in one epoch on how much data we'll work on as there is 8000 images in training set it is set to 8000\n",
    "- third parameter takes how many epochs there will be\n",
    "- fourth parameter will take the set from where it will validate its prediction, i.e. how accurate its prediction is\n",
    "- fifth parameter takes how many images to check on, as we have 2000 images in the test set it is set to 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.save_model(classifier,filepath = 'highly_trained.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('dataset/dog_or_cat.jpeg',\n",
    "                            target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0) # o means that we want to add the dimension in first place\n",
    "\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "elif result[0][0] == 0:\n",
    "    prediction = 'cat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's break down the code\n",
    "- first we are importing the essential library so that we can easily work on the image and apply certain changes like the size and change its dimension\n",
    "- then we load the image using image.load_img(filepath, target_size =(64,64))\n",
    "- then we connvert the image to array\n",
    "- then we expand the dimension of the array as it required by the classifier\n",
    "- then we use predict function of classifier on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
